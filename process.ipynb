{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"> COMP 7630 Group Project </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in e:\\anaconda3\\envs\\common\\lib\\site-packages (1.8.2.2)\n",
      "Requirement already satisfied: numpy>=1.6.1 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from wordcloud) (1.24.2)\n",
      "Requirement already satisfied: pillow in e:\\anaconda3\\envs\\common\\lib\\site-packages (from wordcloud) (9.5.0)\n",
      "Requirement already satisfied: matplotlib in e:\\anaconda3\\envs\\common\\lib\\site-packages (from wordcloud) (3.7.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from matplotlib->wordcloud) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from matplotlib->wordcloud) (1.4.4)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from matplotlib->wordcloud) (5.12.0)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from matplotlib->wordcloud) (23.0)\n",
      "Requirement already satisfied: cycler>=0.10 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from matplotlib->wordcloud) (1.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from matplotlib->wordcloud) (4.39.3)\n",
      "Requirement already satisfied: zipp>=3.1.0 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib->wordcloud) (3.15.0)\n",
      "Requirement already satisfied: six>=1.5 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: spacy in e:\\anaconda3\\envs\\common\\lib\\site-packages (3.5.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: pathy>=0.10.0 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: jinja2 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from spacy) (8.1.9)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from spacy) (0.7.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from spacy) (2.28.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from spacy) (2.4.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from spacy) (6.3.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from spacy) (1.24.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from spacy) (4.65.0)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from spacy) (23.0)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from spacy) (1.1.1)\n",
      "Requirement already satisfied: setuptools in e:\\anaconda3\\envs\\common\\lib\\site-packages (from spacy) (65.6.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from spacy) (1.10.7)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.5.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.15)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\n",
      "Requirement already satisfied: colorama in e:\\anaconda3\\envs\\common\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from jinja2->spacy) (2.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in e:\\anaconda3\\envs\\common\\lib\\site-packages (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.20.3 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from pandas) (1.24.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: bs4 in e:\\anaconda3\\envs\\common\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from bs4) (4.12.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from beautifulsoup4->bs4) (2.3.2.post1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: requests in e:\\anaconda3\\envs\\common\\lib\\site-packages (2.28.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from requests) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from requests) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from requests) (3.1.0)\n",
      "Requirement already satisfied: joblib in e:\\anaconda3\\envs\\common\\lib\\site-packages (1.2.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Collecting en-core-web-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
      "     --------------------------------------- 12.8/12.8 MB 59.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.6.0,>=3.5.0 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from en-core-web-sm==3.5.0) (3.5.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.28.2)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
      "Requirement already satisfied: pathy>=0.10.0 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: setuptools in e:\\anaconda3\\envs\\common\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (65.6.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.24.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: jinja2 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (23.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.7)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.65.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.9)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.15)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: colorama in e:\\anaconda3\\envs\\common\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\anaconda3\\envs\\common\\lib\\site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "%pip install wordcloud\n",
    "%pip install -U spacy\n",
    "%pip install pandas\n",
    "%pip install bs4\n",
    "%pip install requests\n",
    "%pip install joblib\n",
    "%pip install matplotlib\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import re\n",
    "import requests\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Acquirement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movies(name):\n",
    "    url = f'https://www.rottentomatoes.com/browse/{name}/?page=5'\n",
    "    # url = 'https://www.rottentomatoes.com/browse/movies_in_theaters/?page=5'\n",
    "    headers = {\n",
    "        'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36',\n",
    "        'content-type': 'text/html'\n",
    "    }\n",
    "    res = requests.get(url=url, headers=headers)\n",
    "    pattern = r'alt=\"(.*?)\"\\s*class=\"posterImage\"'\n",
    "    matches = re.findall(pattern, res.text)\n",
    "    print(len(matches), 'Movies')\n",
    "    if len(matches) > 0:\n",
    "        for i in range(len(matches)):\n",
    "            matches[i] = matches[i].lower()\n",
    "            matches[i] = re.sub(r\"[^a-zA-Z0-9]+\", \"_\", matches[i])\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comments_movies(name):\n",
    "    url = f'https://www.rottentomatoes.com/m/{name}/reviews'\n",
    "    headers = {\n",
    "        'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36',\n",
    "        'content-type': 'text/html',\n",
    "    }\n",
    "\n",
    "    res = requests.get(url=url, headers=headers)\n",
    "\n",
    "    # Define a regular expression pattern to match the phrase \"review-quote\"\n",
    "    pattern = r'review-quote\">(.*?)<\\/p>'\n",
    "    comments = re.findall(pattern, res.text)\n",
    "    if len(comments) > 0:\n",
    "        for i in range(len(comments)):\n",
    "            comments[i] = re.sub(r'\\d+', '', comments[i])\n",
    "            comments[i] = re.sub(r'[&#;]', '', comments[i])\n",
    "        # print(comments)\n",
    "    pattern = r'hide\" state=\"([^\"]+)\"'\n",
    "    labels = re.findall(pattern, res.text)\n",
    "    # print(labels)\n",
    "    return comments, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movie_data():\n",
    "    infor_dict = {\n",
    "        'movie_name': [],\n",
    "        'movie_comment': [],\n",
    "        'movie_label': []\n",
    "    }\n",
    "    movies = []\n",
    "    movies_type = [\n",
    "        'movies_at_home',\n",
    "        'movies_at_home/sort:popular',\n",
    "        'movies_at_home/sort:audience_highest',\n",
    "        'movies_at_home/sort:audience_lowest',\n",
    "        'movies_at_home/sort:critic_highest',\n",
    "        'movies_at_home/sort:critic_lowest',\n",
    "        'movies_in_theaters',\n",
    "        'movies_in_theaters/sort:popular',\n",
    "        'movies_in_theaters/sort:audience_highest',\n",
    "        'movies_in_theaters/sort:audience_lowest',\n",
    "        'movies_in_theaters/sort:critic_highest',\n",
    "        'movies_in_theaters/sort:critic_lowest',\n",
    "        'tv_series_browse',\n",
    "        'tv_series_browse/sort:popular',\n",
    "        'tv_series_browse/sort:audience_highest',\n",
    "        'tv_series_browse/sort:audience_lowest',\n",
    "        'tv_series_browse/sort:critic_highest',\n",
    "        'tv_series_browse/sort:critic_lowest'\n",
    "    ]\n",
    "    for name in movies_type:\n",
    "        movies += get_movies(name)\n",
    "    print(len(movies), 'total')\n",
    "    for i in range(len(movies)):\n",
    "        comments, labels = get_comments_movies(movies[i])\n",
    "        if i % 100 == 0:\n",
    "            print(i, 'movies be processed')\n",
    "        for j in range(len(comments)):\n",
    "            infor_dict['movie_name'].append(movies[i])\n",
    "            infor_dict['movie_comment'].append(comments[j])\n",
    "            infor_dict['movie_label'].append(labels[j])\n",
    "\n",
    "    df = pd.DataFrame(infor_dict)\n",
    "    df.to_csv('movies.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_games(name):\n",
    "    url = f'https://store.steampowered.com/saleaction/ajaxgetsaledynamicappquery?cc=HK&l=english&clanAccountID=41316928&clanAnnouncementGID=3128313422564004283&flavor=popularpurchased&start={name}&count=150&tabuniqueid=8&sectionuniqueid=93094&return_capsules=true&origin=https:%2F%2Fstore.steampowered.com&bForceUseSaleTag=true&strContentHubType=freetoplay&strTabFilter=&strSectionFilter=%7B%22type%22:0,%22bNegated%22:true,%22rgSubexpressions%22:[%7B%22type%22:7,%22value%22:%22dlc%22%7D]%7D&bPrioritizeDiscounts=false'\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    res = requests.get(url=url, headers=headers)\n",
    "    res_dict = res.json()\n",
    "    games = res_dict['appids']\n",
    "    return games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comments_games(name):\n",
    "    url = f'https://steamcommunity.com/app/{name}/reviews/?browsefilter=toprated&snr=1_5_100010_&filterLanguage=english'\n",
    "    headers = {\n",
    "        'Content-Type': 'text/html',\n",
    "        'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36',\n",
    "    }\n",
    "    res = requests.get(url=url, headers=headers)\n",
    "    # print(res.text)\n",
    "    pattern = r'</div>\\s+(.*?)\\s+</div>\\s+</div>\\s+<div class=\"UserReviewCardContent_Footer\">'\n",
    "    comments = re.findall(pattern, res.text)\n",
    "    # if len(comments) > 0:\n",
    "    #     for i in range(len(comments)):\n",
    "    #         comments[i] = re.sub(r\"[^a-zA-Z\\s]+\", '', comments[i])\n",
    "    pattern = r'<div class=\"title\">(.+?)</div>'\n",
    "    labels = re.findall(pattern, res.text)\n",
    "    return comments, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def game_data():\n",
    "    infor_dict = {\n",
    "        'game_name': [],\n",
    "        'game_comment': [],\n",
    "        'game_label': []\n",
    "    }\n",
    "    games = []\n",
    "    games_type = [i for i in range(0, 2001, 100)]\n",
    "    for name in games_type:\n",
    "        games += get_games(name)\n",
    "    print(len(games), 'total games')\n",
    "    for i in range(len(games)):\n",
    "        comments, labels = get_comments_games(games[i])\n",
    "        if i % 100 == 0:\n",
    "            print(i, 'games be processed')\n",
    "        for j in range(len(comments)):\n",
    "            infor_dict['game_name'].append(games[i])\n",
    "            infor_dict['game_comment'].append(comments[j])\n",
    "            infor_dict['game_label'].append(labels[j])\n",
    "\n",
    "    df = pd.DataFrame(infor_dict)\n",
    "    print(df.shape[0], 'total data')\n",
    "    df.to_csv('games.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data()\n",
    "game_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data & remove empty value row & change type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading movies.csv ...\n",
      "Before dealing with empty value, the shape is: (14050, 3)\n",
      "After dealing with empty value, the shape is: (13735, 3)\n",
      "The head of data is: \n",
      "      name                                            comment   label\n",
      "0  juniper  Filmmakers should showcase Rampling’s indomita...  rotten\n",
      "1  juniper  Savilles directorial debut is solid just like ...   fresh\n",
      "2  juniper  It feels personal in a lot of the details and ...   fresh\n",
      "3  juniper  We've seen this a million times -- but not wit...   fresh\n",
      "4  juniper  Juniper takes some time to get where it is goi...   fresh\n",
      "\n",
      "Reading games.csv ...\n",
      "Before dealing with empty value, the shape is: (11721, 3)\n",
      "After dealing with empty value, the shape is: (11115, 3)\n",
      "The head of data is: \n",
      "  name                                            comment            label\n",
      "0  730  After  years playing it I didnt improve my ski...      Recommended\n",
      "1  730                                     I NOT CAN PLAY  Not Recommended\n",
      "2  730  Your team in every random competitive gamebrbr...      Recommended\n",
      "3  730  gtsee a guybrgtshoot himbrgtmiss every shotbrg...      Recommended\n",
      "4  730  This community is so nice i got a lot of tips ...      Recommended\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def read_data(name):\n",
    "    # print porcess\n",
    "    print(\"Reading\",name,\"...\")\n",
    "    \n",
    "    # read csv\n",
    "    text_data = pd.read_csv(name, header=0)\n",
    "    text_data.columns = [\"name\", \"comment\", \"label\"]\n",
    "\n",
    "    # print process\n",
    "    print(\"Before dealing with empty value, the shape is:\",text_data.shape)\n",
    "\n",
    "    # deal with empty value\n",
    "    text_data[\"comment\"].replace('',np.nan,inplace=True) # replace the empty content to nan\n",
    "    text_data = text_data.dropna(axis=0, how='any') # remove row with nan value\n",
    "\n",
    "    # change type\n",
    "    text_data = text_data.astype(str)\n",
    "\n",
    "    # print process\n",
    "    print(\"After dealing with empty value, the shape is:\",text_data.shape)\n",
    "    print(\"The head of data is: \")\n",
    "    print(text_data.head(),end='\\n\\n')\n",
    "\n",
    "    return text_data\n",
    "\n",
    "movie = read_data(\"movies.csv\")\n",
    "game = read_data(\"games.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing labes\n",
      "Processed labes\n"
     ]
    }
   ],
   "source": [
    "print(\"Processing labes\")\n",
    "game.replace(['Recommended', 'Not Recommended'], ['Positive','Negative'], regex=True , inplace=True)\n",
    "movie.replace(['fresh', 'rotten'], ['Positive','Negative'], regex=True , inplace=True)\n",
    "print(\"Processed labes\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open abbreviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions = {\n",
    "    \"aight\": \"alright\",\n",
    "    \"ain't\": \"am not\",\n",
    "    \"amn't\": \"am not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"can't\": \"can not\",\n",
    "    \"cause\": \"because\",\n",
    "    \"could've\": \"could have\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"couldn't've\": \"could not have\",\n",
    "    \"daren't\": \"dare not\",\n",
    "    \"daresn't\": \"dare not\",\n",
    "    \"dasn't\": \"dare not\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"d'ye\": \"do you\",\n",
    "    \"e'er\": \"ever\",\n",
    "    \"everybody's\": \"everybody is\",\n",
    "    \"everyone's\": \"everyone is\",\n",
    "    \"finna\": \"fixing to\",\n",
    "    \"g'day\": \"good day\",\n",
    "    \"gimme\": \"give me\",\n",
    "    \"giv'n\": \"given\",\n",
    "    \"gonna\": \"going to\",\n",
    "    \"gon't\": \"go not\",\n",
    "    \"gotta\": \"got to\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"had've\": \"had have\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"he'd\": \"he had\",\n",
    "    \"he'dn't've'd\": \"he would not have had\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"he've\": \"he have\",\n",
    "    \"how'd\": \"how would\",\n",
    "    \"howdy\": \"how do you do\",\n",
    "    \"how'll\": \"how will\",\n",
    "    \"how're\": \"how are\",\n",
    "    \"I'll\": \"I will\",\n",
    "    \"I'm\": \"I am\",\n",
    "    \"I'm'a\": \"I am about to\",\n",
    "    \"I'm'o\": \"I am going to\",\n",
    "    \"innit\": \"is it not\",\n",
    "    \"I've\": \"I have\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"it'd\": \"it would\",\n",
    "    \"it'll\": \"it will\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"let's\": \"let us\",\n",
    "    \"ma'am\": \"madam\",\n",
    "    \"mayn't\": \"may not\",\n",
    "    \"may've\": \"may have\",\n",
    "    \"methinks\": \"me thinks\",\n",
    "    \"mightn't\": \"might not\",\n",
    "    \"might've\": \"might have\",\n",
    "    \"mustn't\": \"must not\",\n",
    "    \"mustn't've\": \"must not have\",\n",
    "    \"must've\": \"must have\",\n",
    "    \"needn't\": \"need not\",\n",
    "    \"ne'er\": \"never\",\n",
    "    \"o'clock\": \"of the clock\",\n",
    "    \"o'er\": \"over\",\n",
    "    \"ol'\": \"old\",\n",
    "    \"oughtn't\": \"ought not\",\n",
    "    \"'s\": \"is\",\n",
    "    \"shalln't\": \"shall not\",\n",
    "    \"shan't\": \"shall not\",\n",
    "    \"she'd\": \"she would\",\n",
    "    \"she'll\": \"she shall\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"she's\": \"she has\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"should've\": \"should have\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"shouldn't've\": \"should not have\",\n",
    "    \"somebody's\": \"somebody has\",\n",
    "    \"somebody's\": \"somebody is\",\n",
    "    \"someone's\": \"someone has\",\n",
    "    \"someone's\": \"someone is\",\n",
    "    \"something's\": \"something has\",\n",
    "    \"something's\": \"something is\",\n",
    "    \"so're\": \"so are\",\n",
    "    \"that'll\": \"that shall\",\n",
    "    \"that'll\": \"that will\",\n",
    "    \"that're\": \"that are\",\n",
    "    \"that's\": \"that has\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"that'd\": \"that would\",\n",
    "    \"that'd\": \"that had\",\n",
    "    \"there'd\": \"there had\",\n",
    "    \"there'd\": \"there would\",\n",
    "    \"there'll\": \"there shall\",\n",
    "    \"there'll\": \"there will\",\n",
    "    \"there're\": \"there are\",\n",
    "    \"there's\": \"there has\",\n",
    "    \"there's\": \"there is\",\n",
    "    \"these're\": \"these are\",\n",
    "    \"these've\": \"these have\",\n",
    "    \"they'd\": \"they had\",\n",
    "    \"they'd\": \"they would\",\n",
    "    \"they'll\": \"they shall\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"they're\": \"they were\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"this's\": \"this has\",\n",
    "    \"this's\": \"this is\",\n",
    "    \"those're\": \"those are\",\n",
    "    \"those've\": \"those have\",\n",
    "    \"'tis\": \"it is\",\n",
    "    \"to've\": \"to have\",\n",
    "    \"'twas\": \"it was\",\n",
    "    \"wanna\": \"want to\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"we'd\": \"we had\",\n",
    "    \"we'd\": \"we would\",\n",
    "    \"we'd\": \"we did\",\n",
    "    \"we'll\": \"we shall\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"what'd\": \"what did\",\n",
    "    \"what'll\": \"what shall\",\n",
    "    \"what'll\": \"what will\",\n",
    "    \"what're\": \"what are\",\n",
    "    \"what're\": \"what were\",\n",
    "    \"what's\": \"what has\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"what's\": \"what does\",\n",
    "    \"what've\": \"what have\",\n",
    "    \"when's\": \"when has\",\n",
    "    \"when's\": \"when is\",\n",
    "    \"where'd\": \"where did\",\n",
    "    \"where'll\": \"where shall\",\n",
    "    \"where'll\": \"where will\",\n",
    "    \"where're\": \"where are\",\n",
    "    \"where's\": \"where has\",\n",
    "    \"where's\": \"where is\",\n",
    "    \"where's\": \"where does\",\n",
    "    \"where've\": \"where have\",\n",
    "    \"which'd\": \"which had\",\n",
    "    \"which'd\": \"which would\",\n",
    "    \"which'll\": \"which shall\",\n",
    "    \"which'll\": \"which will\",\n",
    "    \"which're\": \"which are\",\n",
    "    \"which's\": \"which has\",\n",
    "    \"which's\": \"which is\",\n",
    "    \"which've\": \"which have\",\n",
    "    \"who'd\": \"who would\",\n",
    "    \"who'd\": \"who had\",\n",
    "    \"who'd\": \"who did\",\n",
    "    \"who'd've\": \"who would have\",\n",
    "    \"who'll\": \"who shall\",\n",
    "    \"who'll\": \"who will\",\n",
    "    \"who're\": \"who are\",\n",
    "    \"who's\": \"who has\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"who's\": \"who does\",\n",
    "    \"who've\": \"who have\",\n",
    "    \"why'd\": \"why did\",\n",
    "    \"why're\": \"why are\",\n",
    "    \"why's\": \"why has\",\n",
    "    \"why's\": \"why is\",\n",
    "    \"why's\": \"why does\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"would've\": \"would have\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"wouldn't've\": \"would not have\",\n",
    "    \"y'all\": \"you all\",\n",
    "    \"y'all'd've\": \"you all would have\",\n",
    "    \"y'all'dn't've'd\": \"you all would not have had\",\n",
    "    \"y'all're\": \"you all are\",\n",
    "    \"you'd\": \"you had\",\n",
    "    \"you'd\": \"you would\",\n",
    "    \"you'll\": \"you shall\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"you've\": \"you have\",\n",
    "    \" u \": \"you\",\n",
    "    \" ur \": \"your\",\n",
    "    \" n \": \"and\"\n",
    "}\n",
    "\n",
    "def cont_to_exp(x):\n",
    "    if type(x) is str:\n",
    "        for key in contractions:\n",
    "            value = contractions[key]\n",
    "            x = x.replace(key, value)\n",
    "        return x\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "def apply_cont_to_exp(df):\n",
    "    df['comment'] = df['comment'].apply(lambda x: cont_to_exp(x))\n",
    "    return df\n",
    "\n",
    "movie = apply_cont_to_exp(movie)\n",
    "game = apply_cont_to_exp(game)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert spaces to single space, Remove quotation marks, Remove the newline character, Remove br"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_label(df):\n",
    "    df.replace(['\\ +', '\"','\\n','\\r','/br[a-z]+br/g','/b[a-z]+b/g','RT'], [' ',' ','','','','',''], regex=True , inplace=True)\n",
    "    return df\n",
    "\n",
    "game = remove_special_label(game)\n",
    "\n",
    "movie = remove_special_label(movie)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing game data\n",
      "\n",
      "Converting to lower letter\n",
      "Removing HTML\n",
      "Removing emails\n",
      "Removing urls\n",
      "Removing stop words\n",
      "Removing special chars\n",
      "Removing multi spaces\n",
      "Counting words\n",
      "Removing common words\n",
      "Removing rare words\n",
      "\n",
      "Processing movie data\n",
      "\n",
      "Converting to lower letter\n",
      "Removing HTML\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wangk\\AppData\\Local\\Temp\\ipykernel_38056\\1505595802.py:7: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  df['comment'] = df['comment'].apply(lambda x: BeautifulSoup(x, 'lxml').get_text())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing emails\n",
      "Removing urls\n",
      "Removing stop words\n",
      "Removing special chars\n",
      "Removing multi spaces\n",
      "Counting words\n",
      "Removing common words\n",
      "Removing rare words\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(df):\n",
    "    print(\"Converting to lower letter\")\n",
    "    df['comment'] = df['comment'].apply(lambda x: x.lower())\n",
    "\n",
    "    # Remove HTML\n",
    "    print(\"Removing HTML\")\n",
    "    df['comment'] = df['comment'].apply(lambda x: BeautifulSoup(x, 'lxml').get_text())\n",
    "    \n",
    "    # Remove Emails\n",
    "    print(\"Removing emails\")\n",
    "    df['comment'] = df['comment'].apply(lambda x: re.sub(\n",
    "        r'([a-zA-Z0-9+._-]+@[a-zA-Z0-9._-]+\\.[a-zA-Z0-9_-]+)', '', x))\n",
    "\n",
    "    # # Remove urls\n",
    "    print(\"Removing urls\")\n",
    "    df['comment'] = df['comment'].apply(lambda x: re.sub(\n",
    "        r'(http|ftp|https)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?', '', x))\n",
    "    \n",
    "    # Create a spacy Doc object\n",
    "    print(\"Removing stop words\")\n",
    "    df['comment'] = df['comment'].apply(lambda x: ' '.join(\n",
    "        [t for t in x.split() if t not in STOP_WORDS]))\n",
    "    \n",
    "    # Removal of special chars and punctuation\n",
    "    print(\"Removing special chars\")\n",
    "    df['comment'] = df['comment'].apply(\n",
    "        lambda x: re.sub('[^\\w]', ' ', x))\n",
    "    \n",
    "    # Removing multiple spaces\n",
    "    print(\"Removing multi spaces\")\n",
    "    df['comment'] = df['comment'].apply(lambda x: ' '.join(x.split()))\n",
    "\n",
    "    # count words frequency\n",
    "    print(\"Counting words\")\n",
    "    frequency = pd.Series(' '.join(df['comment']).split()).value_counts()\n",
    "\n",
    "    # Remove common words\n",
    "    print(\"Removing common words\")\n",
    "    common = frequency[:10]\n",
    "    df['comment'] = df['comment'].apply(lambda x: \" \".join([t for t in x.split() if t not in common]))\n",
    "\n",
    "    # Remove rare words\n",
    "    print(\"Removing rare words\")\n",
    "    rare = frequency[-10:]\n",
    "    df['comment'] = df['comment'].apply(lambda x: \" \".join([t for t in x.split() if t not in rare]))\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"Processing game data\\n\")\n",
    "game = preprocess_text(game)\n",
    "print(\"\\nProcessing movie data\\n\")\n",
    "movie = preprocess_text(movie)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorization comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def get_vec(x):\n",
    "    doc = nlp(x)\n",
    "    return doc.vector.reshape(1, -1)\n",
    "\n",
    "def vec_data(df):\n",
    "    df['comment'] = df['comment'].apply(lambda x: get_vec(x))\n",
    "    return df\n",
    "\n",
    "game = vec_data(game)\n",
    "movie = vec_data(movie)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Explore data before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "common",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
