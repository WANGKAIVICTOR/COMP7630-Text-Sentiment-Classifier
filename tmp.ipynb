{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wordcloud\n",
    "!pip install - U spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "#data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#text packages\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import spacy\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#model preparation & selection\n",
    "from sklearn.model_selection import validation_curve, train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"movies.csv\"\n",
    "text_data = pd.read_csv(name, header=0)\n",
    "text_data.columns = [\"name\", \"comment\", \"label\"]\n",
    "print(text_data.shape)\n",
    "text_data = text_data.dropna(axis=0, how='any', inplace=False)\n",
    "text_data = text_data.astype(str)\n",
    "text_data.head(), print(text_data.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions = {\n",
    "    \"aight\": \"alright\",\n",
    "    \"ain't\": \"am not\",\n",
    "    \"amn't\": \"am not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"can't\": \"can not\",\n",
    "    \"cause\": \"because\",\n",
    "    \"could've\": \"could have\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"couldn't've\": \"could not have\",\n",
    "    \"daren't\": \"dare not\",\n",
    "    \"daresn't\": \"dare not\",\n",
    "    \"dasn't\": \"dare not\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"d'ye\": \"do you\",\n",
    "    \"e'er\": \"ever\",\n",
    "    \"everybody's\": \"everybody is\",\n",
    "    \"everyone's\": \"everyone is\",\n",
    "    \"finna\": \"fixing to\",\n",
    "    \"g'day\": \"good day\",\n",
    "    \"gimme\": \"give me\",\n",
    "    \"giv'n\": \"given\",\n",
    "    \"gonna\": \"going to\",\n",
    "    \"gon't\": \"go not\",\n",
    "    \"gotta\": \"got to\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"had've\": \"had have\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"he'd\": \"he had\",\n",
    "    \"he'dn't've'd\": \"he would not have had\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"he've\": \"he have\",\n",
    "    \"how'd\": \"how would\",\n",
    "    \"howdy\": \"how do you do\",\n",
    "    \"how'll\": \"how will\",\n",
    "    \"how're\": \"how are\",\n",
    "    \"I'll\": \"I will\",\n",
    "    \"I'm\": \"I am\",\n",
    "    \"I'm'a\": \"I am about to\",\n",
    "    \"I'm'o\": \"I am going to\",\n",
    "    \"innit\": \"is it not\",\n",
    "    \"I've\": \"I have\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"it'd\": \"it would\",\n",
    "    \"it'll\": \"it will\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"let's\": \"let us\",\n",
    "    \"ma'am\": \"madam\",\n",
    "    \"mayn't\": \"may not\",\n",
    "    \"may've\": \"may have\",\n",
    "    \"methinks\": \"me thinks\",\n",
    "    \"mightn't\": \"might not\",\n",
    "    \"might've\": \"might have\",\n",
    "    \"mustn't\": \"must not\",\n",
    "    \"mustn't've\": \"must not have\",\n",
    "    \"must've\": \"must have\",\n",
    "    \"needn't\": \"need not\",\n",
    "    \"ne'er\": \"never\",\n",
    "    \"o'clock\": \"of the clock\",\n",
    "    \"o'er\": \"over\",\n",
    "    \"ol'\": \"old\",\n",
    "    \"oughtn't\": \"ought not\",\n",
    "    \"'s\": \"is\",\n",
    "    \"shalln't\": \"shall not\",\n",
    "    \"shan't\": \"shall not\",\n",
    "    \"she'd\": \"she would\",\n",
    "    \"she'll\": \"she shall\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"she's\": \"she has\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"should've\": \"should have\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"shouldn't've\": \"should not have\",\n",
    "    \"somebody's\": \"somebody has\",\n",
    "    \"somebody's\": \"somebody is\",\n",
    "    \"someone's\": \"someone has\",\n",
    "    \"someone's\": \"someone is\",\n",
    "    \"something's\": \"something has\",\n",
    "    \"something's\": \"something is\",\n",
    "    \"so're\": \"so are\",\n",
    "    \"that'll\": \"that shall\",\n",
    "    \"that'll\": \"that will\",\n",
    "    \"that're\": \"that are\",\n",
    "    \"that's\": \"that has\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"that'd\": \"that would\",\n",
    "    \"that'd\": \"that had\",\n",
    "    \"there'd\": \"there had\",\n",
    "    \"there'd\": \"there would\",\n",
    "    \"there'll\": \"there shall\",\n",
    "    \"there'll\": \"there will\",\n",
    "    \"there're\": \"there are\",\n",
    "    \"there's\": \"there has\",\n",
    "    \"there's\": \"there is\",\n",
    "    \"these're\": \"these are\",\n",
    "    \"these've\": \"these have\",\n",
    "    \"they'd\": \"they had\",\n",
    "    \"they'd\": \"they would\",\n",
    "    \"they'll\": \"they shall\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"they're\": \"they were\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"this's\": \"this has\",\n",
    "    \"this's\": \"this is\",\n",
    "    \"those're\": \"those are\",\n",
    "    \"those've\": \"those have\",\n",
    "    \"'tis\": \"it is\",\n",
    "    \"to've\": \"to have\",\n",
    "    \"'twas\": \"it was\",\n",
    "    \"wanna\": \"want to\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"we'd\": \"we had\",\n",
    "    \"we'd\": \"we would\",\n",
    "    \"we'd\": \"we did\",\n",
    "    \"we'll\": \"we shall\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"what'd\": \"what did\",\n",
    "    \"what'll\": \"what shall\",\n",
    "    \"what'll\": \"what will\",\n",
    "    \"what're\": \"what are\",\n",
    "    \"what're\": \"what were\",\n",
    "    \"what's\": \"what has\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"what's\": \"what does\",\n",
    "    \"what've\": \"what have\",\n",
    "    \"when's\": \"when has\",\n",
    "    \"when's\": \"when is\",\n",
    "    \"where'd\": \"where did\",\n",
    "    \"where'll\": \"where shall\",\n",
    "    \"where'll\": \"where will\",\n",
    "    \"where're\": \"where are\",\n",
    "    \"where's\": \"where has\",\n",
    "    \"where's\": \"where is\",\n",
    "    \"where's\": \"where does\",\n",
    "    \"where've\": \"where have\",\n",
    "    \"which'd\": \"which had\",\n",
    "    \"which'd\": \"which would\",\n",
    "    \"which'll\": \"which shall\",\n",
    "    \"which'll\": \"which will\",\n",
    "    \"which're\": \"which are\",\n",
    "    \"which's\": \"which has\",\n",
    "    \"which's\": \"which is\",\n",
    "    \"which've\": \"which have\",\n",
    "    \"who'd\": \"who would\",\n",
    "    \"who'd\": \"who had\",\n",
    "    \"who'd\": \"who did\",\n",
    "    \"who'd've\": \"who would have\",\n",
    "    \"who'll\": \"who shall\",\n",
    "    \"who'll\": \"who will\",\n",
    "    \"who're\": \"who are\",\n",
    "    \"who's\": \"who has\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"who's\": \"who does\",\n",
    "    \"who've\": \"who have\",\n",
    "    \"why'd\": \"why did\",\n",
    "    \"why're\": \"why are\",\n",
    "    \"why's\": \"why has\",\n",
    "    \"why's\": \"why is\",\n",
    "    \"why's\": \"why does\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"would've\": \"would have\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"wouldn't've\": \"would not have\",\n",
    "    \"y'all\": \"you all\",\n",
    "    \"y'all'd've\": \"you all would have\",\n",
    "    \"y'all'dn't've'd\": \"you all would not have had\",\n",
    "    \"y'all're\": \"you all are\",\n",
    "    \"you'd\": \"you had\",\n",
    "    \"you'd\": \"you would\",\n",
    "    \"you'll\": \"you shall\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"you've\": \"you have\",\n",
    "    \" u \": \"you\",\n",
    "    \" ur \": \"your\",\n",
    "    \" n \": \"and\"\n",
    "}\n",
    "\n",
    "\n",
    "def cont_to_exp(x):\n",
    "    if type(x) is str:\n",
    "        for key in contractions:\n",
    "            value = contractions[key]\n",
    "            x = x.replace(key, value)\n",
    "        return x\n",
    "    else:\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "# Load the spaCy language model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "\n",
    "def preprocess_text(df):\n",
    "    df['comment'] = df['comment'].apply(lambda x: x.lower())\n",
    "\n",
    "    df['comment'] = df['comment'].apply(lambda x: cont_to_exp(x))\n",
    "\n",
    "    # Remove HTML\n",
    "    df['comment'] = df['comment'].apply(\n",
    "        lambda x: BeautifulSoup(x, 'lxml').get_text())\n",
    "    \n",
    "    # Remove Emails\n",
    "    df['comment'] = df['comment'].apply(lambda x: re.sub(\n",
    "        r'([a-zA-Z0-9+._-]+@[a-zA-Z0-9._-]+\\.[a-zA-Z0-9_-]+)', '', x))\n",
    "\n",
    "    # # Remove urls\n",
    "    df['comment'] = df['comment'].apply(lambda x: re.sub(\n",
    "        r'(http|ftp|https)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?', '', x))\n",
    "    \n",
    "    # Create a spaCy Doc object\n",
    "    df['comment'] = df['comment'].apply(lambda x: ' '.join(\n",
    "        [t for t in x.split() if t not in STOP_WORDS]))\n",
    "    \n",
    "    # Removal of special chars and punctuation\n",
    "    df['comment'] = df['comment'].apply(\n",
    "        lambda x: re.sub('[^\\w]', ' ', x))\n",
    "    \n",
    "    # Removing multiple spaces\n",
    "    df['comment'] = df['comment'].apply(lambda x: ' '.join(x.split()))\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# Example usage\n",
    "data = {'comment': [\n",
    "    \"We've this! An -- example <b>text</b> with an email@example.com and some punctuation!!!\"]}\n",
    "test = pd.DataFrame(data)\n",
    "\n",
    "df = preprocess_text(text_data)\n",
    "print(df)  # Output: \"example text email punctuation\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore data before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "text = ' '.join(df['comment'])\n",
    "text = text.split()\n",
    "x = ' '.join(text[:20000])\n",
    "wordcloud_noun = WordCloud(width=2500, height=1800,\n",
    "                           max_words=800,\n",
    "                           background_color='white', collocations=False,\n",
    "                           normalize_plurals=False).generate(x)\n",
    "plt.figure(figsize=(18, 9))\n",
    "plt.imshow(wordcloud_noun, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.title('Most Frequent Nouns', fontsize=20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_df = text_data.copy()\n",
    "\n",
    "new_data_df['Text_Length'] = new_data_df['comment'].str.len()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "ax = sns.histplot(x=new_data_df['Text_Length'], color='darkcyan')\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "plt.xlabel('Number of Characters in Review', fontsize=14)\n",
    "plt.title('Count of Review by Length', fontsize=20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "ax = sns.countplot(x=new_data_df['label'], color='teal')\n",
    "#plt.xlim(0,12000)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "plt.xlabel('Sentiment', fontsize=14)\n",
    "plt.title('Count of Reviews of Each Sentiment', fontsize=20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are '+ str(text_data[text_data['label']=='fresh'].shape[0])+' positive reviews.')\n",
    "print('There are '+ str(text_data[text_data['label']!='fresh'].shape[0]) + ' negative reviews.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = \"fresh\"\n",
    "vec = TfidfVectorizer(stop_words='english', min_df=7,\n",
    "                      ngram_range=(1, 2), max_df=0.8)\n",
    "X_data = vec.fit_transform(df['comment'])\n",
    "df['sentiment_score'] = np.where(\n",
    "    df['label'] == labels, 1, 0)\n",
    "Y_data = df['sentiment_score']\n",
    "\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(\n",
    "    X_data, Y_data, test_size=0.15, random_state=0)\n",
    "\n",
    "#Support Vector Machine (not cross-validating here)\n",
    "clf = SVC(kernel='rbf', probability=True).fit(Xtrain, Ytrain)\n",
    "clf_score = clf.score(Xtest, Ytest)\n",
    "\n",
    "\n",
    "# # Train the SVM classifier\n",
    "# classifier = SVC(kernel='linear')\n",
    "# classifier.fit(vectorized_sentences, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The accuracy for the kernel SVC model is '+str(clf_score))\n",
    "clf_f1score = f1_score(Ytest, clf.predict(Xtest))\n",
    "print('The F1 for the kernel SVC model is '+str(clf_f1score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(clf, \"%s.pkl\" % name.split(\".\")[0])\n",
    "joblib.dump(vec, \"%s.pkl\" % name.split(\".\")[0]+\"_vec\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = joblib.load(\"%s.pkl\" % name.split(\".\")[0])\n",
    "pkl_vec = joblib.load(\"%s.pkl\" % name.split(\".\")[0]+\"_vec\")\n",
    "# Test on a new sentence\n",
    "\n",
    "\n",
    "def test(clf, vec, text):\n",
    "    test_vectorized_sentence = vec.transform([text])\n",
    "    prediction = clf.predict(test_vectorized_sentence)\n",
    "    # Output: [1] (positive sentiment)\n",
    "    print(prediction, clf.predict_proba(\n",
    "        test_vectorized_sentence)[0][prediction[0]])\n",
    "\n",
    "\n",
    "test(estimator, pkl_vec, \"This movie is shit\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
